{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "837a1c48-0b4d-40d3-80a6-3d676154889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from langchain_chroma import Chroma\n",
    "from langchain_unstructured import UnstructuredLoader\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f347627d-a268-4f47-a950-ed4a675eaa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_PATH = '/Users/keithatienza/Desktop/Academics/Emergent Consulting [HPE]/HPE LLM v2/HPE Files/'\n",
    "CHROMA_PATH = '/Users/keithatienza/Desktop/Academics/Emergent Consulting [HPE]/HPE LLM v2/DB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57dc8e28-4cf6-48eb-91e3-99fdce963b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = \"mxbai-embed-large\"\n",
    "llm_model = \"llama3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65cfa9e6-5dd6-4871-a555-d403daebea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based on the context above: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecfa2e93-38ad-462c-beec-5130686b10e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 819c2adf5ce6... 100% ▕████████████████▏ 669 MB                         \n",
      "pulling c71d239df917... 100% ▕████████████████▏  11 KB                         \n",
      "pulling b837481ff855... 100% ▕████████████████▏   16 B                         \n",
      "pulling 38badd946f91... 100% ▕████████████████▏  408 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "!ollama pull mxbai-embed-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32676b46-666f-40a5-89ff-609ef64614ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 6a0746a1ec1a... 100% ▕████████████████▏ 4.7 GB                         \n",
      "pulling 4fa551d4f938... 100% ▕████████████████▏  12 KB                         \n",
      "pulling 8ab4849b038c... 100% ▕████████████████▏  254 B                         \n",
      "pulling 577073ffcc6c... 100% ▕████████████████▏  110 B                         \n",
      "pulling 3f8eb4da87fa... 100% ▕████████████████▏  485 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3992d9c7-fc94-4e44-91df-a32a054fc48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents():\n",
    "    docs = []\n",
    "    for file in os.listdir(FOLDER_PATH):\n",
    "        if file.endswith('.pdf'):\n",
    "            pdf_path = FOLDER_PATH + \"/\" + file\n",
    "            loader = UnstructuredLoader(pdf_path)\n",
    "            docs.extend(loader.load())\n",
    "    docs = filter_complex_metadata(docs)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=200)\n",
    "    chunks = text_splitter.split_documents(docs)\n",
    "    chunks = [c for c in chunks if c.metadata.get('category') != 'Header'] # customized to remove repetitive headers of product name, may not be generalizable\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9f92ca2-4cff-4960-9dfe-93f401ed68b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_database(docs):\n",
    "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=OllamaEmbeddings(model=embed_model))\n",
    "    db.add_documents(docs)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bcdeb86-4e34-4a12-bc85-ed46f99856e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rag(query_text, db):\n",
    "    results = db.similarity_search_with_score(query_text, k=20)\n",
    "    context_text = \"\\n\\n---\\n\\n\".join([\"Product:\" + docs.metadata.get(\"filename\")[:-7] + \"\\n\\n\" + docs.page_content for docs, _score in results])\n",
    "    #print(results)\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "    prompt = prompt.format(context=context_text, question=query_text)\n",
    "    \n",
    "    model = OllamaLLM(model=\"llama3\")\n",
    "    response_text = model.invoke(prompt)\n",
    "    formatted_response = f\"Response: {response_text} \\n\\n\"\n",
    "    #print(formatted_response)\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13f5fde9-269b-430e-9277-568b9b1a1570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: pikepdf C++ to Python logger bridge initialized\n"
     ]
    }
   ],
   "source": [
    "docs = load_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71ae6b67-ad92-496b-b444-92db42d5c701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "db = populate_database(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e9d3454-9dd2-40cd-bd17-06c4ec5c4ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided context, the NVIDIA RTX 4000 Ada Graphics Accelerator for HPE is supported in the following HPE ProLiant servers:\n",
      "\n",
      "* Product:HPE ProLiant ML350 Gen11-a50004308\n",
      "* Product:HPE ProLiant DL380 Gen11-a50004307 (with some limitations)\n",
      "\n",
      "So, yes, the RTX 4000 GPU is supported in at least two HPE server models.\n"
     ]
    }
   ],
   "source": [
    "query = \"Is the RTX 4000 GPU supported in any of HPE’s server models?\" \n",
    "print(query_rag(query,db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4bab6df2-43fc-4ff6-82ec-c9494cd54140",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the first product description, the HPE ProLiant DL380a Gen11 server is \"accelerator optimized\" and supports 4 double-wide or 8 single-wide accelerators in a standard 2U 2P form factor.\n",
      "\n",
      "Additionally, from the Accelerator Intel Data Center GPU Max 1100 48GB Accelerator for HPE notes, it's mentioned that this accelerator is supported in the front GPU cages of DL380a Gen11 4 Double Wide CTO Server (P54903-B21) only. This suggests that the server has at least 2 GPU cages.\n",
      "\n",
      "Given these details, we can conclude that a Proliant DL380a Gen11 server can fit up to 8 single-wide GPUs or 4 double-wide GPUs.\n"
     ]
    }
   ],
   "source": [
    "query = \"How many GPUs can fit in a Proliant DL380a Gen11 server?\"\n",
    "print(query_rag(query,db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d299f82a-508e-4036-99cf-b1287723b082",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context, I would recommend the HPE ProLiant ML350 Gen11-a50004308enw as the best option for the customer.\n",
      "\n",
      "According to the product information, this server has a Form Factor of 4U Tower, which means it can be used as a standalone tower server. Additionally, it has an Optional Tower-to-Rack conversion kit (P47394-B21) that can convert the unit to a 5U Rack-mount server if needed.\n",
      "\n",
      "Since the customer has limited space in their datacenter and no rack currently, using the server as a tower would be the best option. This way, they can still have a powerful server without taking up too much space. If they decide to upgrade or expand their infrastructure in the future, the tower-to-rack conversion kit provides an easy upgrade path.\n",
      "\n",
      "The other servers mentioned (HPE ProLiant DL325 Gen11-a50004297enw and HPE ProLiant DL360 Gen11-a50004306enw) are all rack-mount servers, which might not be suitable for a customer with limited space.\n"
     ]
    }
   ],
   "source": [
    "query = \"The customer has limited space in it’s datacenter and also no rack currently. Which server model would best fit its needs?\"\n",
    "print(query_rag(query,db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13391d50-8978-4741-87a9-8735b9976748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, I can answer your question.\n",
      "\n",
      "According to the product information, the HPE ProLiant DL380 Gen11 supports 5th Generation Intel Xeon Processors. Specifically, the \"HPE ProLiant DL380 Gen11 5418Y 2.0GHz 24-core 1P 64GB-R MR408i-o NC 8SFF 800W PS Server\" has a CPU with 24 cores.\n",
      "\n",
      "Therefore, the answer is: The CPU available for the DL380 Gen11 that has the highest amount of cores is the 5418Y with 24 cores.\n"
     ]
    }
   ],
   "source": [
    "query = \"Which CPU available for the DL380 Gen11 has the highest amount of cores, and how many does it have?\"\n",
    "print(query_rag(query,db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a943f599-fc96-46b1-bde1-6fb6099de952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context provided, it appears that the 5th Generation Intel Xeon Processors are supported by the HPE ProLiant DL380 Gen11 server. According to the specifications for these processors, they support up to 28 cores.\n",
      "\n",
      "However, there is also a mention of \"4th and 5th Generation Intel Xeon Scalable Processors\" in the context, which suggests that the processor family includes multiple generations with varying core counts. The exact model number of the CPU is not provided in the context, but it appears that the highest amount of cores available for the DL380 Gen11 server is up to 28 cores.\n",
      "\n",
      "It's important to note that the actual CPU model and specifications may vary depending on the specific configuration or upgrade options chosen.\n"
     ]
    }
   ],
   "source": [
    "query = \"Which CPU available for the DL380 Gen11 has the highest amount of cores, and what is the maximum core that you can install?\"\n",
    "print(query_rag(query,db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e05b7513-36a0-4c37-aaf0-4cd90825d5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, there is no specific information about the number of memory channels for the HPE ProLiant DL360 Gen11. However, we can infer that it supports up to 5600 MT/s HPE DDR5 Smart Memory up to 4.0 TB per socket, which suggests a high-density memory architecture.\n"
     ]
    }
   ],
   "source": [
    "query = \"How many memory channels does the DL360 Gen 11 have?\"\n",
    "print(query_rag(query,db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2702b88c-2eee-4c8b-8c03-33e155d2d8e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d15ba42-63fb-4814-ac99-a5f227ee5094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978ae290-71c1-4cbf-8989-d022b7cae849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf26936-a7d2-4160-a197-a735d38de1ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
