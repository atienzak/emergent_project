{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "837a1c48-0b4d-40d3-80a6-3d676154889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from langchain_chroma import Chroma\n",
    "from langchain_unstructured import UnstructuredLoader\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f347627d-a268-4f47-a950-ed4a675eaa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_PATH = '/Users/keithatienza/Desktop/Academics/Emergent Consulting [HPE]/HPE LLM v2/HPE Files/'\n",
    "CHROMA_PATH = '/Users/keithatienza/Desktop/Academics/Emergent Consulting [HPE]/HPE LLM v2/DB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57dc8e28-4cf6-48eb-91e3-99fdce963b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = \"mxbai-embed-large\"\n",
    "llm_model = \"llama3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65cfa9e6-5dd6-4871-a555-d403daebea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based on the context above: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecfa2e93-38ad-462c-beec-5130686b10e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 819c2adf5ce6... 100% ▕████████████████▏ 669 MB                         \n",
      "pulling c71d239df917... 100% ▕████████████████▏  11 KB                         \n",
      "pulling b837481ff855... 100% ▕████████████████▏   16 B                         \n",
      "pulling 38badd946f91... 100% ▕████████████████▏  408 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "!ollama pull mxbai-embed-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32676b46-666f-40a5-89ff-609ef64614ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 6a0746a1ec1a... 100% ▕████████████████▏ 4.7 GB                         \n",
      "pulling 4fa551d4f938... 100% ▕████████████████▏  12 KB                         \n",
      "pulling 8ab4849b038c... 100% ▕████████████████▏  254 B                         \n",
      "pulling 577073ffcc6c... 100% ▕████████████████▏  110 B                         \n",
      "pulling 3f8eb4da87fa... 100% ▕████████████████▏  485 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3992d9c7-fc94-4e44-91df-a32a054fc48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents():\n",
    "    docs = []\n",
    "    for file in os.listdir(FOLDER_PATH):\n",
    "        if file.endswith('.pdf'):\n",
    "            pdf_path = FOLDER_PATH + \"/\" + file\n",
    "            loader = UnstructuredLoader(pdf_path)\n",
    "            docs.extend(loader.load())\n",
    "    docs = filter_complex_metadata(docs)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=200)\n",
    "    chunks = text_splitter.split_documents(docs)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9f92ca2-4cff-4960-9dfe-93f401ed68b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_database(docs):\n",
    "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=OllamaEmbeddings(model=embed_model))\n",
    "    db.add_documents(docs)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6bcdeb86-4e34-4a12-bc85-ed46f99856e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rag(query_text, db):\n",
    "    results = db.similarity_search_with_score(query_text, k=20)\n",
    "    context_text = \"\\n\\n---\\n\\n\".join([\"Product:\" + docs.metadata.get(\"filename\")[:-4] + \"\\n\\n\" + docs.page_content for docs, _score in results])\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "    prompt = prompt.format(context=context_text, question=query_text)\n",
    "    \n",
    "    model = OllamaLLM(model=\"llama3\")\n",
    "    response_text = model.invoke(prompt)\n",
    "    formatted_response = f\"Response: {response_text} \\n\\n\"\n",
    "    #print(formatted_response)\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13f5fde9-269b-430e-9277-568b9b1a1570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: pikepdf C++ to Python logger bridge initialized\n",
      "INFO: Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "docs = load_documents()\n",
    "db = populate_database(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7e9d3454-9dd2-40cd-bd17-06c4ec5c4ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Is the RTX 4000 GPU supported in any of HPE’s server models?\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "95e3c8d6-cd61-4c34-b374-1df8d516005f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided context, the NVIDIA RTX 4000 Ada Graphics Accelerator for HPE is supported in the following servers:\n",
      "\n",
      "1. Product:HPE ProLiant ML350 Gen11-a50004308enw\n",
      "2. Product:HPE ProLiant DL380 Gen11-a50004307enw\n",
      "\n",
      "Therefore, yes, the RTX 4000 GPU is supported in at least two of HPE's server models: the ML350 and the DL380.\n"
     ]
    }
   ],
   "source": [
    "print(query_rag(query,db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bab6df2-43fc-4ff6-82ec-c9494cd54140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d299f82a-508e-4036-99cf-b1287723b082",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13391d50-8978-4741-87a9-8735b9976748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a943f599-fc96-46b1-bde1-6fb6099de952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05b7513-36a0-4c37-aaf0-4cd90825d5f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2702b88c-2eee-4c8b-8c03-33e155d2d8e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d15ba42-63fb-4814-ac99-a5f227ee5094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978ae290-71c1-4cbf-8989-d022b7cae849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf26936-a7d2-4160-a197-a735d38de1ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
